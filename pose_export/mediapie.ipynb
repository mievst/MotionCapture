{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:\\\\Users\\\\mievst\\\\Desktop\\\\masters\\\\pose_export\\\\pose_landmarker_full.task'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Create a pose landmarker instance with the video mode:\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    output_segmentation_masks=True,\n",
    "    running_mode=VisionRunningMode.VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_name = [\n",
    "    \"nose\", \n",
    "    \"left_eye_inner\",\n",
    "    \"left_eye\",\n",
    "    \"left_eye_outer\",\n",
    "    \"right_eye_inner\",\n",
    "    \"right_eye\",\n",
    "    \"right_eye_outer\",\n",
    "    \"left_ear\", \n",
    "    \"right_ear\", \n",
    "    \"mouth_left\", \n",
    "    \"mouth_right\", \n",
    "    \"left_shoulder\", \n",
    "    \"right_shoulder\", \n",
    "    \"left_elbow\", \n",
    "    \"right_elbow\", \n",
    "    \"left_wrist\", \n",
    "    \"right_wrist\", \n",
    "    \"left_pinky\", \n",
    "    \"right_pinky\", \n",
    "    \"left_index\", \n",
    "    \"right_index\", \n",
    "    \"left_thumb\", \n",
    "    \"right_thumb\", \n",
    "    \"left_hip\", \n",
    "    \"right_hip\", \n",
    "    \"left_knee\", \n",
    "    \"right_knee\", \n",
    "    \"left_ankle\", \n",
    "    \"right_ankle\",\n",
    "    \"left_heel\",\n",
    "    \"right_heel\",\n",
    "    \"left_foot_index\", \n",
    "    \"right_foot_index\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "# Use OpenCV’s VideoCapture to load the input video.\n",
    "# Load the video file\n",
    "cap = cv2.VideoCapture(\"Танец - Made with Clipchamp.mp4\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "offset = []\n",
    "i = 0\n",
    "depth_map_meters = None\n",
    "focal_length = 0.05\n",
    "while True:\n",
    "  ret, frame = cap.read()\n",
    "  if not ret:\n",
    "    break\n",
    "  if depth_map_meters is None:\n",
    "    # Читаем глубину из первого кадра\n",
    "    depth_map = np.asanyarray(frame, dtype=np.float32)\n",
    "\n",
    "    # Масштабируем глубину в метры\n",
    "    depth_scale = 3\n",
    "    depth_map_meters = depth_map * depth_scale\n",
    "  mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "  \n",
    "  with PoseLandmarker.create_from_options(options) as landmarker:\n",
    "  # The landmarker is initialized. Use it here.\n",
    "  # ...\n",
    "    results = landmarker.detect_for_video(mp_image, i)\n",
    "    if results.segmentation_masks == None:\n",
    "      continue\n",
    "    # поиск пикселей, принадлежащих объекту\n",
    "    indices = np.where(results.segmentation_masks[0].numpy_view() == 1)\n",
    "\n",
    "    # нахождение самой верхней и самой нижней точек объекта\n",
    "    top_point = (np.min(indices[0]), np.mean(indices[1][np.where(indices[0] == np.min(indices[0]))]))\n",
    "    bottom_point = (np.max(indices[0]), np.mean(indices[1][np.where(indices[0] == np.max(indices[0]))]))\n",
    "    landmarks = np.zeros((len(results.pose_landmarks[0]), 3))\n",
    "    for j, landmark in enumerate(results.pose_landmarks[0]):\n",
    "      z_meter = landmark.z * depth_map_meters.mean()\n",
    "      x_pix = (landmark.x + 1) / 2 * size[0] + size[0] / 2\n",
    "      y_pix = (landmark.y + 1) / 2 * size[1] + size[1] / 2\n",
    "      landmarks[j] = [x_pix, z_meter, y_pix]\n",
    "    landmarks = [landmarks]\n",
    "    landmarks = np.array(landmarks)\n",
    "    if len(offset) == 0:\n",
    "      center = np.mean(landmarks, axis=(0, 1))\n",
    "\n",
    "      offset = -center\n",
    "\n",
    "    landmarks += offset\n",
    "\n",
    "    for landmark in landmarks:\n",
    "      # Draw the pose of the person on the current frame\n",
    "      if results.pose_landmarks:\n",
    "        frame_pose = {\n",
    "          \"frame\": i,\n",
    "          \"pose\": {}\n",
    "          }\n",
    "        for j in range(len(bone_name)):\n",
    "          frame_pose[\"pose\"][bone_name[j]] = {\n",
    "            \"x\": landmark[j][0],\n",
    "            \"y\": landmark[j][1],\n",
    "            \"z\": landmark[j][2],\n",
    "            }\n",
    "          #cv2.circle(frame, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "          frame_pose[\"box\"] = {\n",
    "                  \"x_min\": int(bottom_point[1]),\n",
    "                  \"y_min\": int(bottom_point[0]),\n",
    "                  \"x_max\": int(top_point[1]),\n",
    "                  \"y_max\": int(top_point[0])\n",
    "                  }\n",
    "        poses.append(frame_pose)\n",
    "\n",
    "\t# Display the current frame\n",
    "\t#cv2.imshow(\"Frame\", frame)\n",
    "  i+=1\n",
    "\n",
    "\t# Check if the user wants to quit\n",
    "  if cv2.waitKey(1) & 0xFF == 27:\n",
    "    break\n",
    "\n",
    "# Close the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data : list, window_size):\n",
    "    new_data = data.copy()\n",
    "    for name in bone_name:\n",
    "        x_array = np.zeros(len(data) + 2 * window_size)\n",
    "        y_array = np.zeros(len(data) + 2 * window_size)\n",
    "        z_array = np.zeros(len(data) + 2 * window_size)\n",
    "        for i in range(len(data)):\n",
    "            x_array[i + window_size] = data[i][\"pose\"][name][\"x\"]\n",
    "            y_array[i + window_size] = data[i][\"pose\"][name][\"y\"]\n",
    "            z_array[i + window_size] = data[i][\"pose\"][name][\"z\"]\n",
    "        # Добавить значения в начало и конец массивов\n",
    "        for i in range(window_size):\n",
    "            x_array[i] = x_array[window_size]\n",
    "            y_array[i] = y_array[window_size]\n",
    "            z_array[i] = z_array[window_size]\n",
    "            x_array[-i-1] = x_array[-window_size-1]\n",
    "            y_array[-i-1] = y_array[-window_size-1]\n",
    "            z_array[-i-1] = z_array[-window_size-1]\n",
    "        window = np.ones(window_size) / window_size\n",
    "        x_array = np.convolve(x_array, window, mode='valid')\n",
    "        y_array = np.convolve(y_array, window, mode='valid')\n",
    "        z_array = np.convolve(z_array, window, mode='valid')\n",
    "        for i in range(len(data)):\n",
    "            new_data[i][\"pose\"][name][\"x\"] = x_array[i]\n",
    "            new_data[i][\"pose\"][name][\"y\"] = y_array[i]\n",
    "            new_data[i][\"pose\"][name][\"z\"] = z_array[i]\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "poses = moving_average(poses, 5)\n",
    "with open(\"poses.json\", \"w\") as f:\n",
    "\tjson.dump(poses, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MediaPipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
