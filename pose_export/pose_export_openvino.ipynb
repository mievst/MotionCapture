{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openvino.runtime import Core\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"./engine\")\n",
    "#import engine.engine3js as engine\n",
    "from engine.parse_poses import parse_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# model name as named in Open Model Zoo\n",
    "model_name = \"human-pose-estimation-3d-0001\"\n",
    "# selected precision (FP32, FP16)\n",
    "precision = \"FP32\"\n",
    "\n",
    "BASE_MODEL_NAME = f\"{base_model_dir}/public/{model_name}/{model_name}\"\n",
    "model_path = Path(BASE_MODEL_NAME).with_suffix(\".pth\")\n",
    "onnx_path = Path(BASE_MODEL_NAME).with_suffix(\".onnx\")\n",
    "\n",
    "ir_model_path = f\"model/public/{model_name}/{precision}/{model_name}.xml\"\n",
    "model_weights_path = f\"model/public/{model_name}/{precision}/{model_name}.bin\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    download_command = (\n",
    "        f\"omz_downloader \" f\"--name {model_name} \" f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $download_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not onnx_path.exists():\n",
    "    convert_command = (\n",
    "        f\"omz_converter \"\n",
    "        f\"--name {model_name} \"\n",
    "        f\"--precisions {precision} \"\n",
    "        f\"--download_dir {base_model_dir} \"\n",
    "        f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $convert_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize inference engine\n",
    "ie_core = Core()\n",
    "# read the network and corresponding weights from file\n",
    "model = ie_core.read_model(model=ir_model_path, weights=model_weights_path)\n",
    "# load the model on the CPU (you can use GPU or MYRIAD as well)\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "infer_request = compiled_model.create_infer_request()\n",
    "input_tensor_name = model.inputs[0].get_any_name()\n",
    "\n",
    "# get input and output names of nodes\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layers = list(compiled_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading person-detection-retail-0013 ||################\n",
      "\n",
      "========== Downloading model\\intel\\person-detection-retail-0013\\FP32\\person-detection-retail-0013.xml\n",
      "... 100%, 374 KB, 2002 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading model\\intel\\person-detection-retail-0013\\FP32\\person-detection-retail-0013.bin\n",
      "... 36%, 1024 KB, 3447 KB/s, 0 seconds passed\n",
      "... 72%, 2048 KB, 4366 KB/s, 0 seconds passed\n",
      "... 100%, 2823 KB, 4753 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading model\\intel\\person-detection-retail-0013\\FP16\\person-detection-retail-0013.xml\n",
      "... 100%, 557 KB, 2748 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading model\\intel\\person-detection-retail-0013\\FP16\\person-detection-retail-0013.bin\n",
      "... 72%, 1024 KB, 3864 KB/s, 0 seconds passed\n",
      "... 100%, 1411 KB, 4525 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading model\\intel\\person-detection-retail-0013\\FP16-INT8\\person-detection-retail-0013.xml\n",
      "... 99%, 1024 KB, 3849 KB/s, 0 seconds passed\n",
      "... 100%, 1028 KB, 3660 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading model\\intel\\person-detection-retail-0013\\FP16-INT8\\person-detection-retail-0013.bin\n",
      "... 100%, 757 KB, 3031 KB/s, 0 seconds passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# directory where model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# model name as named in Open Model Zoo\n",
    "model_name = \"person-detection-retail-0013\"\n",
    "# selected precision (FP32, FP16)\n",
    "precision = \"FP32\"\n",
    "\n",
    "BASE_MODEL_NAME = f\"{base_model_dir}/intel/{model_name}/FP32/{model_name}\"\n",
    "model_path = Path(BASE_MODEL_NAME).with_suffix(\".pth\")\n",
    "onnx_path = Path(BASE_MODEL_NAME).with_suffix(\".onnx\")\n",
    "\n",
    "ir_model_path = f\"model/intel/{model_name}/{precision}/{model_name}.xml\"\n",
    "model_weights_path = f\"model/intel/{model_name}/{precision}/{model_name}.bin\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    download_command = (\n",
    "        f\"omz_downloader \" f\"--name {model_name} \" f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $download_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Skipping person-detection-retail-0013 (no conversions defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not onnx_path.exists():\n",
    "    convert_command = (\n",
    "        f\"omz_converter \"\n",
    "        f\"--name {model_name} \"\n",
    "        f\"--precisions {precision} \"\n",
    "        f\"--download_dir {base_model_dir} \"\n",
    "        f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $convert_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the network and corresponding weights from file\n",
    "model_object_detection = ie_core.read_model(model=ir_model_path, weights=model_weights_path)\n",
    "# load the model on the CPU (you can use GPU or MYRIAD as well)\n",
    "compiled_model_object_detection = ie_core.compile_model(model=model_object_detection, device_name=\"CPU\")\n",
    "infer_request_object_detection = compiled_model_object_detection.create_infer_request()\n",
    "input_tensor_name_object_detection = model_object_detection.inputs[0].get_any_name()\n",
    "\n",
    "# get input and output names of nodes\n",
    "input_layer_object_detection = compiled_model_object_detection.input(0)\n",
    "output_layers_object_detection = list(compiled_model_object_detection.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"Танец - Made with Clipchamp.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_edges = np.array(\n",
    "    [\n",
    "        [0, 1], \n",
    "        [0, 9], [9, 10], [10, 11],    # neck - r_shoulder - r_elbow - r_wrist\n",
    "        [0, 3], [3, 4], [4, 5],       # neck - l_shoulder - l_elbow - l_wrist\n",
    "        [1, 15], [15, 16],            # nose - l_eye - l_ear\n",
    "        [1, 17], [17, 18],            # nose - r_eye - r_ear\n",
    "        [0, 6], [6, 7], [7, 8],       # neck - l_hip - l_knee - l_ankle\n",
    "        [0, 12], [12, 13], [13, 14],  # neck - r_hip - r_knee - r_ankle\n",
    "    ]\n",
    ")\n",
    "\n",
    "focal_length = -1  # default\n",
    "stride = 8\n",
    "player = None\n",
    "skeleton_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "i = 0\n",
    "offset = []\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    input_image = cv2.resize(frame, (input_layer.shape[3], input_layer.shape[2]))\n",
    "    input_image = input_image.transpose((2, 0, 1))  # change data layout from HWC to CHW\n",
    "    input_image = input_image.reshape(input_layer.shape)  # reshape to input shape\n",
    "    # run inference\n",
    "    infer_request.infer({input_tensor_name: input_image})\n",
    "\n",
    "    # detection human\n",
    "    input_image_object_detection = cv2.resize(frame, (input_layer_object_detection.shape[3], input_layer_object_detection.shape[2]))\n",
    "    input_image_object_detection = input_image_object_detection.transpose((2, 0, 1))  # change data layout from HWC to CHW\n",
    "    input_image_object_detection = input_image_object_detection.reshape(input_layer_object_detection.shape)  # reshape to input shape\n",
    "    # run inference\n",
    "    detection_res = infer_request_object_detection.infer({input_tensor_name: input_image_object_detection})\n",
    "    boxes = infer_request_object_detection.get_tensor(\"detection_out\").data[:][0][0]\n",
    "\n",
    "    x_min = y_min = x_max = y_max = 0\n",
    "    for box in boxes:\n",
    "        confidence = box[2]\n",
    "        if confidence > 0.5 and box[1] == 1:\n",
    "            x_min = int(box[3] * input_image_object_detection.shape[3])\n",
    "            y_min = int(box[4] * input_image_object_detection.shape[2])\n",
    "            x_max = int(box[5] * input_image_object_detection.shape[3])\n",
    "            y_max = int(box[6] * input_image_object_detection.shape[2])\n",
    "\n",
    "    # A set of three inference results is obtained\n",
    "    results = {\n",
    "        name: infer_request.get_tensor(name).data[:]\n",
    "        for name in {\"features\", \"heatmaps\", \"pafs\"}\n",
    "    }\n",
    "    # Get the results\n",
    "    results = (results[\"features\"][0], results[\"heatmaps\"][0], results[\"pafs\"][0])\n",
    "    poses_3d, poses_2d = parse_poses(results, 1, stride, focal_length, True)\n",
    "    if len(poses_3d) > 0:\n",
    "                # From here, you can rotate the 3D point positions using the function \"draw_poses\",\n",
    "                # or you can directly make the correct mapping below to properly display the object image on the screen\n",
    "                poses_3d_copy = poses_3d.copy()\n",
    "                x = poses_3d_copy[:, 0::4]\n",
    "                y = poses_3d_copy[:, 1::4]\n",
    "                z = poses_3d_copy[:, 2::4]\n",
    "                poses_3d[:, 0::4], poses_3d[:, 1::4], poses_3d[:, 2::4] = (\n",
    "                    -z + np.ones(poses_3d[:, 2::4].shape) * 200,\n",
    "                    -y + np.ones(poses_3d[:, 2::4].shape) * 100,\n",
    "                    -x,\n",
    "                )\n",
    "\n",
    "                poses_3d = poses_3d.reshape(poses_3d.shape[0], 19, -1)[:, :, 0:3]\n",
    "                poses_3d = poses_3d.astype(float)\n",
    "                if  len(offset) == 0:\n",
    "                    # Find the center of the skeleton\n",
    "                    center = np.mean(poses_3d, axis=(0, 1))\n",
    "\n",
    "                    # Compute the offset to move the skeleton to the origin\n",
    "                    offset = -center\n",
    "\n",
    "                # Apply the offset to all points of the skeleton\n",
    "                poses_3d += offset\n",
    "\n",
    "    for pose_3d in poses_3d:\n",
    "        frame_pose = {\n",
    "            \"frame\": i,\n",
    "            \"pose\": {\n",
    "                \"neck\": {\"y\":pose_3d[0][0], \"z\":pose_3d[0][1], \"x\":pose_3d[0][2]},\n",
    "                \"right_shoulder\": {\"y\":pose_3d[9][0], \"z\":pose_3d[9][1], \"x\":pose_3d[9][2]},\n",
    "                \"right_elbow\": {\"y\":pose_3d[10][0], \"z\":pose_3d[10][1], \"x\":pose_3d[10][2]},\n",
    "                \"right_wrist\": {\"y\":pose_3d[11][0], \"z\":pose_3d[11][1], \"x\":pose_3d[11][2]},\n",
    "                \"left_shoulder\": {\"y\":pose_3d[3][0], \"z\":pose_3d[3][1], \"x\":pose_3d[3][2]},\n",
    "                \"left_elbow\": {\"y\":pose_3d[4][0], \"z\":pose_3d[4][1], \"x\":pose_3d[4][2]},\n",
    "                \"left_wrist\": {\"y\":pose_3d[5][0], \"z\":pose_3d[5][1], \"x\":pose_3d[5][2]},\n",
    "                \"left_eye\": {\"y\":pose_3d[15][0], \"z\":pose_3d[15][1], \"x\":pose_3d[15][2]},\n",
    "                \"left_ear\": {\"y\":pose_3d[16][0], \"z\":pose_3d[16][1], \"x\":pose_3d[16][2]},\n",
    "                \"right_eye\": {\"y\":pose_3d[17][0], \"z\":pose_3d[17][1], \"x\":pose_3d[17][2]},\n",
    "                \"right_ear\": {\"y\":pose_3d[18][0], \"z\":pose_3d[18][1], \"x\":pose_3d[18][2]},\n",
    "                \"nose\": {\"y\":pose_3d[1][0], \"z\":pose_3d[1][1], \"x\":pose_3d[1][2]},\n",
    "                \"left_hip\": {\"y\":pose_3d[6][0], \"z\":pose_3d[6][1], \"x\":pose_3d[6][2]},\n",
    "                \"left_knee\": {\"y\":pose_3d[7][0], \"z\":pose_3d[7][1], \"x\":pose_3d[7][2]},\n",
    "                \"left_ankle\": {\"y\":pose_3d[8][0], \"z\":pose_3d[8][1], \"x\":pose_3d[8][2]},\n",
    "                \"right_hip\": {\"y\":pose_3d[12][0], \"z\":pose_3d[12][1], \"x\":pose_3d[12][2]},\n",
    "                \"right_knee\": {\"y\":pose_3d[13][0], \"z\":pose_3d[13][1], \"x\":pose_3d[13][2]},\n",
    "                \"right_ankle\": {\"y\":pose_3d[14][0], \"z\":pose_3d[14][1], \"x\":pose_3d[14][2]}\n",
    "            },\n",
    "            \"box\": {\n",
    "                \"x_min\": x_min,\n",
    "                \"y_min\": y_min,\n",
    "                \"x_max\": x_max,\n",
    "                \"y_max\": y_max\n",
    "            }\n",
    "        }\n",
    "        poses.append(frame_pose)\n",
    "    i += 1\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_name = [\"neck\", \"right_shoulder\", \"right_elbow\", \"right_wrist\", \"left_shoulder\", \"left_elbow\", \"left_wrist\", \"left_eye\", \"left_ear\", \"right_eye\", \"right_ear\", \"nose\", \"left_hip\", \"left_knee\", \"left_ankle\", \"right_hip\", \"right_knee\", \"right_ankle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data : list, window_size):\n",
    "    new_data = data.copy()\n",
    "    for name in bone_name:\n",
    "        x_array = np.zeros(len(data) + 2 * window_size)\n",
    "        y_array = np.zeros(len(data) + 2 * window_size)\n",
    "        z_array = np.zeros(len(data) + 2 * window_size)\n",
    "        for i in range(len(data)):\n",
    "            x_array[i + window_size] = data[i][\"pose\"][name][\"x\"]\n",
    "            y_array[i + window_size] = data[i][\"pose\"][name][\"y\"]\n",
    "            z_array[i + window_size] = data[i][\"pose\"][name][\"z\"]\n",
    "        # Добавить значения в начало и конец массивов\n",
    "        for i in range(window_size):\n",
    "            x_array[i] = x_array[window_size]\n",
    "            y_array[i] = y_array[window_size]\n",
    "            z_array[i] = z_array[window_size]\n",
    "            x_array[-i-1] = x_array[-window_size-1]\n",
    "            y_array[-i-1] = y_array[-window_size-1]\n",
    "            z_array[-i-1] = z_array[-window_size-1]\n",
    "        window = np.ones(window_size) / window_size\n",
    "        x_array = np.convolve(x_array, window, mode='valid')\n",
    "        y_array = np.convolve(y_array, window, mode='valid')\n",
    "        z_array = np.convolve(z_array, window, mode='valid')\n",
    "        for i in range(len(data)):\n",
    "            new_data[i][\"pose\"][name][\"x\"] = x_array[i]\n",
    "            new_data[i][\"pose\"][name][\"y\"] = y_array[i]\n",
    "            new_data[i][\"pose\"][name][\"z\"] = z_array[i]\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = moving_average(poses, 15)\n",
    "with open(\"poses.json\", \"w\") as f:\n",
    "\tjson.dump(poses, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
