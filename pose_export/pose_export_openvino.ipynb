{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openvino.runtime import Core\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"./engine\")\n",
    "#import engine.engine3js as engine\n",
    "from engine.parse_poses import parse_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# model name as named in Open Model Zoo\n",
    "model_name = \"human-pose-estimation-3d-0001\"\n",
    "# selected precision (FP32, FP16)\n",
    "precision = \"FP32\"\n",
    "\n",
    "BASE_MODEL_NAME = f\"{base_model_dir}/public/{model_name}/{model_name}\"\n",
    "model_path = Path(BASE_MODEL_NAME).with_suffix(\".pth\")\n",
    "onnx_path = Path(BASE_MODEL_NAME).with_suffix(\".onnx\")\n",
    "\n",
    "ir_model_path = f\"model/public/{model_name}/{precision}/{model_name}.xml\"\n",
    "model_weights_path = f\"model/public/{model_name}/{precision}/{model_name}.bin\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    download_command = (\n",
    "        f\"omz_downloader \" f\"--name {model_name} \" f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $download_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not onnx_path.exists():\n",
    "    convert_command = (\n",
    "        f\"omz_converter \"\n",
    "        f\"--name {model_name} \"\n",
    "        f\"--precisions {precision} \"\n",
    "        f\"--download_dir {base_model_dir} \"\n",
    "        f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $convert_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize inference engine\n",
    "ie_core = Core()\n",
    "# read the network and corresponding weights from file\n",
    "model = ie_core.read_model(model=ir_model_path, weights=model_weights_path)\n",
    "# load the model on the CPU (you can use GPU or MYRIAD as well)\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "infer_request = compiled_model.create_infer_request()\n",
    "input_tensor_name = model.inputs[0].get_any_name()\n",
    "\n",
    "# get input and output names of nodes\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layers = list(compiled_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('0327.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_edges = np.array(\n",
    "    [\n",
    "        [0, 1], \n",
    "        [0, 9], [9, 10], [10, 11],    # neck - r_shoulder - r_elbow - r_wrist\n",
    "        [0, 3], [3, 4], [4, 5],       # neck - l_shoulder - l_elbow - l_wrist\n",
    "        [1, 15], [15, 16],            # nose - l_eye - l_ear\n",
    "        [1, 17], [17, 18],            # nose - r_eye - r_ear\n",
    "        [0, 6], [6, 7], [7, 8],       # neck - l_hip - l_knee - l_ankle\n",
    "        [0, 12], [12, 13], [13, 14],  # neck - r_hip - r_knee - r_ankle\n",
    "    ]\n",
    ")\n",
    "\n",
    "focal_length = -1  # default\n",
    "stride = 8\n",
    "player = None\n",
    "skeleton_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "i = 0\n",
    "offset = []\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    input_image = cv2.resize(frame, (input_layer.shape[3], input_layer.shape[2]))\n",
    "    input_image = input_image.transpose((2, 0, 1))  # change data layout from HWC to CHW\n",
    "    input_image = input_image.reshape(input_layer.shape)  # reshape to input shape\n",
    "    # run inference\n",
    "    infer_request.infer({input_tensor_name: input_image})\n",
    "\n",
    "    # A set of three inference results is obtained\n",
    "    results = {\n",
    "        name: infer_request.get_tensor(name).data[:]\n",
    "        for name in {\"features\", \"heatmaps\", \"pafs\"}\n",
    "    }\n",
    "    # Get the results\n",
    "    results = (results[\"features\"][0], results[\"heatmaps\"][0], results[\"pafs\"][0])\n",
    "    poses_3d, poses_2d = parse_poses(results, 1, stride, focal_length, True)\n",
    "    if len(poses_3d) > 0:\n",
    "                # From here, you can rotate the 3D point positions using the function \"draw_poses\",\n",
    "                # or you can directly make the correct mapping below to properly display the object image on the screen\n",
    "                poses_3d_copy = poses_3d.copy()\n",
    "                x = poses_3d_copy[:, 0::4]\n",
    "                y = poses_3d_copy[:, 1::4]\n",
    "                z = poses_3d_copy[:, 2::4]\n",
    "                poses_3d[:, 0::4], poses_3d[:, 1::4], poses_3d[:, 2::4] = (\n",
    "                    -z + np.ones(poses_3d[:, 2::4].shape) * 200,\n",
    "                    -y + np.ones(poses_3d[:, 2::4].shape) * 100,\n",
    "                    -x,\n",
    "                )\n",
    "\n",
    "                poses_3d = poses_3d.reshape(poses_3d.shape[0], 19, -1)[:, :, 0:3]\n",
    "                poses_3d = poses_3d.astype(float)\n",
    "                if len(offset) == 0:\n",
    "                    # Find the center of the skeleton\n",
    "                    center = np.mean(poses_3d, axis=(0, 1))\n",
    "\n",
    "                    # Compute the offset to move the skeleton to the origin\n",
    "                    offset = -center\n",
    "\n",
    "                # Apply the offset to all points of the skeleton\n",
    "                poses_3d += offset\n",
    "\n",
    "    for pose_3d in poses_3d:\n",
    "        frame_pose = {\n",
    "            \"frame\": i,\n",
    "            \"pose\": {\n",
    "                \"neck\": {\"y\":pose_3d[0][0], \"z\":pose_3d[0][1], \"x\":pose_3d[0][2]},\n",
    "                \"r_shoulder\": {\"y\":pose_3d[9][0], \"z\":pose_3d[9][1], \"x\":pose_3d[9][2]},\n",
    "                \"r_elbow\": {\"y\":pose_3d[10][0], \"z\":pose_3d[10][1], \"x\":pose_3d[10][2]},\n",
    "                \"r_wrist\": {\"y\":pose_3d[11][0], \"z\":pose_3d[11][1], \"x\":pose_3d[11][2]},\n",
    "                \"l_shoulder\": {\"y\":pose_3d[3][0], \"z\":pose_3d[3][1], \"x\":pose_3d[3][2]},\n",
    "                \"l_elbow\": {\"y\":pose_3d[4][0], \"z\":pose_3d[4][1], \"x\":pose_3d[4][2]},\n",
    "                \"l_wrist\": {\"y\":pose_3d[5][0], \"z\":pose_3d[5][1], \"x\":pose_3d[5][2]},\n",
    "                \"l_eye\": {\"y\":pose_3d[15][0], \"z\":pose_3d[15][1], \"x\":pose_3d[15][2]},\n",
    "                \"l_ear\": {\"y\":pose_3d[16][0], \"z\":pose_3d[16][1], \"x\":pose_3d[16][2]},\n",
    "                \"r_eye\": {\"y\":pose_3d[17][0], \"z\":pose_3d[17][1], \"x\":pose_3d[17][2]},\n",
    "                \"r_ear\": {\"y\":pose_3d[18][0], \"z\":pose_3d[18][1], \"x\":pose_3d[18][2]},\n",
    "                \"nose\": {\"y\":pose_3d[1][0], \"z\":pose_3d[1][1], \"x\":pose_3d[1][2]},\n",
    "                \"l_hip\": {\"y\":pose_3d[6][0], \"z\":pose_3d[6][1], \"x\":pose_3d[6][2]},\n",
    "                \"l_knee\": {\"y\":pose_3d[7][0], \"z\":pose_3d[7][1], \"x\":pose_3d[7][2]},\n",
    "                \"l_ankle\": {\"y\":pose_3d[8][0], \"z\":pose_3d[8][1], \"x\":pose_3d[8][2]},\n",
    "                \"r_hip\": {\"y\":pose_3d[12][0], \"z\":pose_3d[12][1], \"x\":pose_3d[12][2]},\n",
    "                \"r_knee\": {\"y\":pose_3d[13][0], \"z\":pose_3d[13][1], \"x\":pose_3d[13][2]},\n",
    "                \"r_ankle\": {\"y\":pose_3d[14][0], \"z\":pose_3d[14][1], \"x\":pose_3d[14][2]}\n",
    "            }\n",
    "        }\n",
    "        poses.append(frame_pose)\n",
    "    i += 1\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"poses.json\", \"w\") as f:\n",
    "\tjson.dump(poses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame': 0,\n",
       " 'pose': {'neck': {'y': -3.4301187615645574,\n",
       "   'z': 26.738197326660156,\n",
       "   'x': -2.4005995047719857},\n",
       "  'r_shoulder': {'y': -6.78200169613487,\n",
       "   'z': 26.99492645263672,\n",
       "   'x': 10.722807382282458},\n",
       "  'r_elbow': {'y': 0.8295095343338801,\n",
       "   'z': 11.432426452636719,\n",
       "   'x': 25.990328286823473},\n",
       "  'r_wrist': {'y': 17.70267847964638,\n",
       "   'z': 21.21147918701172,\n",
       "   'x': 12.698721383747301},\n",
       "  'l_shoulder': {'y': -1.0552713494551824,\n",
       "   'z': 26.593650817871094,\n",
       "   'x': -17.40291264182643},\n",
       "  'l_elbow': {'y': 10.36936549136513,\n",
       "   'z': 7.322731018066406,\n",
       "   'x': -23.152106787029066},\n",
       "  'l_wrist': {'y': 28.553035535310443,\n",
       "   'z': 19.34674835205078,\n",
       "   'x': -8.225517298045911},\n",
       "  'l_eye': {'y': 13.980403699372943,\n",
       "   'z': 39.93053436279297,\n",
       "   'x': -0.8614001525075814},\n",
       "  'l_ear': {'y': 5.737727918122943,\n",
       "   'z': 39.55748748779297,\n",
       "   'x': -8.068892027202406},\n",
       "  'r_eye': {'y': 14.102245130037005,\n",
       "   'z': 42.219032287597656,\n",
       "   'x': 4.376554940876208},\n",
       "  'r_ear': {'y': 6.172786511872943,\n",
       "   'z': 42.98400115966797,\n",
       "   'x': 6.542812799152575},\n",
       "  'nose': {'y': 14.718822278474505,\n",
       "   'z': 40.25067901611328,\n",
       "   'x': 0.24587485664769204},\n",
       "  'l_hip': {'y': -9.048282824064557,\n",
       "   'z': -20.157989501953125,\n",
       "   'x': -12.094060446086683},\n",
       "  'l_knee': {'y': -15.572605333830182,\n",
       "   'z': -56.32969665527344,\n",
       "   'x': -13.173767591777601},\n",
       "  'l_ankle': {'y': -25.584827623869245,\n",
       "   'z': -91.39677429199219,\n",
       "   'x': -18.218109632793226},\n",
       "  'r_hip': {'y': -7.071018419767682,\n",
       "   'z': -17.848655700683594,\n",
       "   'x': 11.551929925617419},\n",
       "  'r_knee': {'y': -11.499927721525495,\n",
       "   'z': -53.769508361816406,\n",
       "   'x': 14.622658227619372},\n",
       "  'r_ankle': {'y': -20.95680638363487,\n",
       "   'z': -89.17644500732422,\n",
       "   'x': 18.506454919513903}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses_file = []\n",
    "with open(\"C:\\\\Users\\\\mievst\\\\Desktop\\\\masters\\\\pose_export\\\\poses.json\", \"r\") as f:\n",
    "    poses_file = json.loads(f.read())\n",
    "poses_file[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
