{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openvino.runtime import Core\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"./engine\")\n",
    "#import engine.engine3js as engine\n",
    "from engine.parse_poses import parse_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# model name as named in Open Model Zoo\n",
    "model_name = \"human-pose-estimation-3d-0001\"\n",
    "# selected precision (FP32, FP16)\n",
    "precision = \"FP32\"\n",
    "\n",
    "BASE_MODEL_NAME = f\"{base_model_dir}/public/{model_name}/{model_name}\"\n",
    "model_path = Path(BASE_MODEL_NAME).with_suffix(\".pth\")\n",
    "onnx_path = Path(BASE_MODEL_NAME).with_suffix(\".onnx\")\n",
    "\n",
    "ir_model_path = f\"model/public/{model_name}/{precision}/{model_name}.xml\"\n",
    "model_weights_path = f\"model/public/{model_name}/{precision}/{model_name}.bin\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    download_command = (\n",
    "        f\"omz_downloader \" f\"--name {model_name} \" f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $download_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not onnx_path.exists():\n",
    "    convert_command = (\n",
    "        f\"omz_converter \"\n",
    "        f\"--name {model_name} \"\n",
    "        f\"--precisions {precision} \"\n",
    "        f\"--download_dir {base_model_dir} \"\n",
    "        f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $convert_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize inference engine\n",
    "ie_core = Core()\n",
    "# read the network and corresponding weights from file\n",
    "model = ie_core.read_model(model=ir_model_path, weights=model_weights_path)\n",
    "# load the model on the CPU (you can use GPU or MYRIAD as well)\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "infer_request = compiled_model.create_infer_request()\n",
    "input_tensor_name = model.inputs[0].get_any_name()\n",
    "\n",
    "# get input and output names of nodes\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layers = list(compiled_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('0327.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_edges = np.array(\n",
    "    [\n",
    "        [0, 1], \n",
    "        [0, 9], [9, 10], [10, 11],    # neck - r_shoulder - r_elbow - r_wrist\n",
    "        [0, 3], [3, 4], [4, 5],       # neck - l_shoulder - l_elbow - l_wrist\n",
    "        [1, 15], [15, 16],            # nose - l_eye - l_ear\n",
    "        [1, 17], [17, 18],            # nose - r_eye - r_ear\n",
    "        [0, 6], [6, 7], [7, 8],       # neck - l_hip - l_knee - l_ankle\n",
    "        [0, 12], [12, 13], [13, 14],  # neck - r_hip - r_knee - r_ankle\n",
    "    ]\n",
    ")\n",
    "\n",
    "focal_length = -1  # default\n",
    "stride = 8\n",
    "player = None\n",
    "skeleton_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "i = 0\n",
    "offset = []\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    input_image = cv2.resize(frame, (input_layer.shape[3], input_layer.shape[2]))\n",
    "    input_image = input_image.transpose((2, 0, 1))  # change data layout from HWC to CHW\n",
    "    input_image = input_image.reshape(input_layer.shape)  # reshape to input shape\n",
    "    # run inference\n",
    "    infer_request.infer({input_tensor_name: input_image})\n",
    "\n",
    "    # A set of three inference results is obtained\n",
    "    results = {\n",
    "        name: infer_request.get_tensor(name).data[:]\n",
    "        for name in {\"features\", \"heatmaps\", \"pafs\"}\n",
    "    }\n",
    "    # Get the results\n",
    "    results = (results[\"features\"][0], results[\"heatmaps\"][0], results[\"pafs\"][0])\n",
    "    poses_3d, poses_2d = parse_poses(results, 1, stride, focal_length, True)\n",
    "    if len(poses_3d) > 0:\n",
    "                # From here, you can rotate the 3D point positions using the function \"draw_poses\",\n",
    "                # or you can directly make the correct mapping below to properly display the object image on the screen\n",
    "                poses_3d_copy = poses_3d.copy()\n",
    "                x = poses_3d_copy[:, 0::4]\n",
    "                y = poses_3d_copy[:, 1::4]\n",
    "                z = poses_3d_copy[:, 2::4]\n",
    "                poses_3d[:, 0::4], poses_3d[:, 1::4], poses_3d[:, 2::4] = (\n",
    "                    -z + np.ones(poses_3d[:, 2::4].shape) * 200,\n",
    "                    -y + np.ones(poses_3d[:, 2::4].shape) * 100,\n",
    "                    -x,\n",
    "                )\n",
    "\n",
    "                poses_3d = poses_3d.reshape(poses_3d.shape[0], 19, -1)[:, :, 0:3]\n",
    "                poses_3d = poses_3d.astype(float)\n",
    "                if len(offset) == 0:\n",
    "                    # Find the center of the skeleton\n",
    "                    center = np.mean(poses_3d, axis=(0, 1))\n",
    "\n",
    "                    # Compute the offset to move the skeleton to the origin\n",
    "                    offset = -center\n",
    "\n",
    "                # Apply the offset to all points of the skeleton\n",
    "                poses_3d += offset\n",
    "\n",
    "    for pose_3d in poses_3d:\n",
    "        frame_pose = {\n",
    "            \"frame\": i,\n",
    "            \"pose\": {\n",
    "                \"neck\": {\"y\":pose_3d[0][0], \"z\":pose_3d[0][1], \"x\":pose_3d[0][2]},\n",
    "                \"r_shoulder\": {\"y\":pose_3d[9][0], \"z\":pose_3d[9][1], \"x\":pose_3d[9][2]},\n",
    "                \"r_elbow\": {\"y\":pose_3d[10][0], \"z\":pose_3d[10][1], \"x\":pose_3d[10][2]},\n",
    "                \"r_wrist\": {\"y\":pose_3d[11][0], \"z\":pose_3d[11][1], \"x\":pose_3d[11][2]},\n",
    "                \"l_shoulder\": {\"y\":pose_3d[3][0], \"z\":pose_3d[3][1], \"x\":pose_3d[3][2]},\n",
    "                \"l_elbow\": {\"y\":pose_3d[4][0], \"z\":pose_3d[4][1], \"x\":pose_3d[4][2]},\n",
    "                \"l_wrist\": {\"y\":pose_3d[5][0], \"z\":pose_3d[5][1], \"x\":pose_3d[5][2]},\n",
    "                \"l_eye\": {\"y\":pose_3d[15][0], \"z\":pose_3d[15][1], \"x\":pose_3d[15][2]},\n",
    "                \"l_ear\": {\"y\":pose_3d[16][0], \"z\":pose_3d[16][1], \"x\":pose_3d[16][2]},\n",
    "                \"r_eye\": {\"y\":pose_3d[17][0], \"z\":pose_3d[17][1], \"x\":pose_3d[17][2]},\n",
    "                \"r_ear\": {\"y\":pose_3d[18][0], \"z\":pose_3d[18][1], \"x\":pose_3d[18][2]},\n",
    "                \"nose\": {\"y\":pose_3d[1][0], \"z\":pose_3d[1][1], \"x\":pose_3d[1][2]},\n",
    "                \"l_hip\": {\"y\":pose_3d[6][0], \"z\":pose_3d[6][1], \"x\":pose_3d[6][2]},\n",
    "                \"l_knee\": {\"y\":pose_3d[7][0], \"z\":pose_3d[7][1], \"x\":pose_3d[7][2]},\n",
    "                \"l_ankle\": {\"y\":pose_3d[8][0], \"z\":pose_3d[8][1], \"x\":pose_3d[8][2]},\n",
    "                \"r_hip\": {\"y\":pose_3d[12][0], \"z\":pose_3d[12][1], \"x\":pose_3d[12][2]},\n",
    "                \"r_knee\": {\"y\":pose_3d[13][0], \"z\":pose_3d[13][1], \"x\":pose_3d[13][2]},\n",
    "                \"r_ankle\": {\"y\":pose_3d[14][0], \"z\":pose_3d[14][1], \"x\":pose_3d[14][2]}\n",
    "            }\n",
    "        }\n",
    "        poses.append(frame_pose)\n",
    "    i += 1\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_name = [\"neck\", \"r_shoulder\", \"r_elbow\", \"r_wrist\", \"l_shoulder\", \"l_elbow\", \"l_wrist\", \"l_eye\", \"l_ear\", \"r_eye\", \"r_ear\", \"nose\", \"l_hip\", \"l_knee\", \"l_ankle\", \"r_hip\", \"r_knee\", \"r_ankle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data : list, window_size):\n",
    "    new_data = data.copy()\n",
    "    for name in bone_name:\n",
    "        x_array = np.zeros(len(data))\n",
    "        y_array = np.zeros(len(data))\n",
    "        z_array = np.zeros(len(data))\n",
    "        for i in range(len(data)):\n",
    "            x_array[i] = data[i][\"pose\"][name][\"x\"]\n",
    "            y_array[i] = data[i][\"pose\"][name][\"y\"]\n",
    "            z_array[i] = data[i][\"pose\"][name][\"z\"]\n",
    "        window = np.ones(window_size) / window_size\n",
    "        x_array = np.convolve(x_array, window, mode='same')\n",
    "        y_array = np.convolve(y_array, window, mode='same')\n",
    "        z_array = np.convolve(z_array, window, mode='same')\n",
    "        for i in range(len(data)):\n",
    "            new_data[i][\"pose\"][name][\"x\"] = x_array[i]\n",
    "            new_data[i][\"pose\"][name][\"y\"] = y_array[i]\n",
    "            new_data[i][\"pose\"][name][\"z\"] = z_array[i]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "poses = moving_average(poses, 15)\n",
    "with open(\"poses.json\", \"w\") as f:\n",
    "\tjson.dump(poses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame': 0,\n",
       " 'pose': {'neck': {'y': -1.8215934351870904,\n",
       "   'z': 14.39837817811129,\n",
       "   'x': -1.1863718911221155},\n",
       "  'r_shoulder': {'y': -2.1462557073225073,\n",
       "   'z': 14.798808475962854,\n",
       "   'x': 5.840554594575313},\n",
       "  'r_elbow': {'y': -0.9495414332339652,\n",
       "   'z': 8.853952722382125,\n",
       "   'x': 17.04074660100435},\n",
       "  'r_wrist': {'y': 5.129904977898847,\n",
       "   'z': 12.239664392304,\n",
       "   'x': 16.383362491507278},\n",
       "  'l_shoulder': {'y': -2.0685426946271943,\n",
       "   'z': 15.056831547251917,\n",
       "   'x': -8.905923051060292},\n",
       "  'l_elbow': {'y': 1.1696592096696805,\n",
       "   'z': 8.392819909882125,\n",
       "   'x': -17.86967508834705},\n",
       "  'l_wrist': {'y': 8.401175729851971,\n",
       "   'z': 10.674493086965459,\n",
       "   'x': -19.457883239210695},\n",
       "  'l_eye': {'y': 7.276687407911869,\n",
       "   'z': 22.516839278371705,\n",
       "   'x': -0.8804706180304814},\n",
       "  'l_ear': {'y': 1.7990649306983262,\n",
       "   'z': 20.9259447064316,\n",
       "   'x': -3.7591081861864057},\n",
       "  'r_eye': {'y': 6.859045195997806,\n",
       "   'z': 23.287898441783167,\n",
       "   'x': 1.4878085211703649},\n",
       "  'r_ear': {'y': 3.367016387404055,\n",
       "   'z': 22.966824019582646,\n",
       "   'x': 3.059228809256302},\n",
       "  'nose': {'y': 7.317878000359784,\n",
       "   'z': 22.336478357147747,\n",
       "   'x': -0.3929044330329229},\n",
       "  'l_hip': {'y': -4.510157481411049,\n",
       "   'z': -10.818938004343135,\n",
       "   'x': -6.196804891448272},\n",
       "  'l_knee': {'y': -8.437702647426674,\n",
       "   'z': -30.201989050078815,\n",
       "   'x': -7.03346495968208},\n",
       "  'l_ankle': {'y': -14.00396139579907,\n",
       "   'z': -48.36052227354887,\n",
       "   'x': -11.11775375249093},\n",
       "  'r_hip': {'y': -3.0351432398745906,\n",
       "   'z': -10.184190181263709,\n",
       "   'x': 5.643221703746862},\n",
       "  'r_knee': {'y': -5.249916799444902,\n",
       "   'z': -29.496810217071,\n",
       "   'x': 6.663765247244584},\n",
       "  'r_ankle': {'y': -10.509499318976154,\n",
       "   'z': -48.62222830789131,\n",
       "   'x': 7.673404097138789}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses_file = []\n",
    "with open(\"C:\\\\Users\\\\mievst\\\\Desktop\\\\masters\\\\pose_export\\\\poses.json\", \"r\") as f:\n",
    "    poses_file = json.loads(f.read())\n",
    "poses_file[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
