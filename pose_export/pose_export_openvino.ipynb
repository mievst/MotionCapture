{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openvino.runtime import Core\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"./engine\")\n",
    "#import engine.engine3js as engine\n",
    "from engine.parse_poses import parse_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# model name as named in Open Model Zoo\n",
    "model_name = \"human-pose-estimation-3d-0001\"\n",
    "# selected precision (FP32, FP16)\n",
    "precision = \"FP32\"\n",
    "\n",
    "BASE_MODEL_NAME = f\"{base_model_dir}/public/{model_name}/{model_name}\"\n",
    "model_path = Path(BASE_MODEL_NAME).with_suffix(\".pth\")\n",
    "onnx_path = Path(BASE_MODEL_NAME).with_suffix(\".onnx\")\n",
    "\n",
    "ir_model_path = f\"model/public/{model_name}/{precision}/{model_name}.xml\"\n",
    "model_weights_path = f\"model/public/{model_name}/{precision}/{model_name}.bin\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    download_command = (\n",
    "        f\"omz_downloader \" f\"--name {model_name} \" f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $download_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not onnx_path.exists():\n",
    "    convert_command = (\n",
    "        f\"omz_converter \"\n",
    "        f\"--name {model_name} \"\n",
    "        f\"--precisions {precision} \"\n",
    "        f\"--download_dir {base_model_dir} \"\n",
    "        f\"--output_dir {base_model_dir}\"\n",
    "    )\n",
    "    ! $convert_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize inference engine\n",
    "ie_core = Core()\n",
    "# read the network and corresponding weights from file\n",
    "model = ie_core.read_model(model=ir_model_path, weights=model_weights_path)\n",
    "# load the model on the CPU (you can use GPU or MYRIAD as well)\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "infer_request = compiled_model.create_infer_request()\n",
    "input_tensor_name = model.inputs[0].get_any_name()\n",
    "\n",
    "# get input and output names of nodes\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layers = list(compiled_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('selena.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_edges = np.array(\n",
    "    [\n",
    "        [0, 1], \n",
    "        [0, 9], [9, 10], [10, 11],    # neck - r_shoulder - r_elbow - r_wrist\n",
    "        [0, 3], [3, 4], [4, 5],       # neck - l_shoulder - l_elbow - l_wrist\n",
    "        [1, 15], [15, 16],            # nose - l_eye - l_ear\n",
    "        [1, 17], [17, 18],            # nose - r_eye - r_ear\n",
    "        [0, 6], [6, 7], [7, 8],       # neck - l_hip - l_knee - l_ankle\n",
    "        [0, 12], [12, 13], [13, 14],  # neck - r_hip - r_knee - r_ankle\n",
    "    ]\n",
    ")\n",
    "\n",
    "focal_length = -1  # default\n",
    "stride = 8\n",
    "player = None\n",
    "skeleton_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "i = 0\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    input_image = cv2.resize(frame, (input_layer.shape[3], input_layer.shape[2]))\n",
    "    input_image = input_image.transpose((2, 0, 1))  # change data layout from HWC to CHW\n",
    "    input_image = input_image.reshape(input_layer.shape)  # reshape to input shape\n",
    "    # run inference\n",
    "    infer_request.infer({input_tensor_name: input_image})\n",
    "\n",
    "    # A set of three inference results is obtained\n",
    "    results = {\n",
    "        name: infer_request.get_tensor(name).data[:]\n",
    "        for name in {\"features\", \"heatmaps\", \"pafs\"}\n",
    "    }\n",
    "    # Get the results\n",
    "    results = (results[\"features\"][0], results[\"heatmaps\"][0], results[\"pafs\"][0])\n",
    "    poses_3d, poses_2d = parse_poses(results, 1, stride, focal_length, True)\n",
    "    if len(poses_3d) > 0:\n",
    "                # From here, you can rotate the 3D point positions using the function \"draw_poses\",\n",
    "                # or you can directly make the correct mapping below to properly display the object image on the screen\n",
    "                poses_3d_copy = poses_3d.copy()\n",
    "                x = poses_3d_copy[:, 0::4]\n",
    "                y = poses_3d_copy[:, 1::4]\n",
    "                z = poses_3d_copy[:, 2::4]\n",
    "                poses_3d[:, 0::4], poses_3d[:, 1::4], poses_3d[:, 2::4] = (\n",
    "                    -z + np.ones(poses_3d[:, 2::4].shape) * 200,\n",
    "                    -y + np.ones(poses_3d[:, 2::4].shape) * 100,\n",
    "                    -x,\n",
    "                )\n",
    "\n",
    "                poses_3d = poses_3d.reshape(poses_3d.shape[0], 19, -1)[:, :, 0:3]\n",
    "                poses_3d = poses_3d.astype(float)\n",
    "    for pose_3d in poses_3d:\n",
    "        frame_pose = {\n",
    "            \"frame\": i,\n",
    "            \"pose\": {\n",
    "                \"neck\": {\"z\":pose_3d[0][0], \"y\":pose_3d[0][1], \"x\":pose_3d[0][2]},\n",
    "                \"r_shoulder\": {\"z\":pose_3d[9][0], \"y\":pose_3d[9][1], \"x\":pose_3d[9][2]},\n",
    "                \"r_elbow\": {\"z\":pose_3d[10][0], \"y\":pose_3d[10][1], \"x\":pose_3d[10][2]},\n",
    "                \"r_wrist\": {\"z\":pose_3d[11][0], \"y\":pose_3d[11][1], \"x\":pose_3d[11][2]},\n",
    "                \"l_shoulder\": {\"z\":pose_3d[3][0], \"y\":pose_3d[3][1], \"x\":pose_3d[3][2]},\n",
    "                \"l_elbow\": {\"z\":pose_3d[4][0], \"y\":pose_3d[4][1], \"x\":pose_3d[4][2]},\n",
    "                \"l_wrist\": {\"z\":pose_3d[5][0], \"y\":pose_3d[5][1], \"x\":pose_3d[5][2]},\n",
    "                \"l_eye\": {\"z\":pose_3d[15][0], \"y\":pose_3d[15][1], \"x\":pose_3d[15][2]},\n",
    "                \"l_ear\": {\"z\":pose_3d[16][0], \"y\":pose_3d[16][1], \"x\":pose_3d[16][2]},\n",
    "                \"r_eye\": {\"z\":pose_3d[17][0], \"y\":pose_3d[17][1], \"x\":pose_3d[17][2]},\n",
    "                \"r_ear\": {\"z\":pose_3d[18][0], \"y\":pose_3d[18][1], \"x\":pose_3d[18][2]},\n",
    "                \"nose\": {\"z\":pose_3d[1][0], \"y\":pose_3d[1][1], \"x\":pose_3d[1][2]},\n",
    "                \"l_hip\": {\"z\":pose_3d[6][0], \"y\":pose_3d[6][1], \"x\":pose_3d[6][2]},\n",
    "                \"l_knee\": {\"z\":pose_3d[7][0], \"y\":pose_3d[7][1], \"x\":pose_3d[7][2]},\n",
    "                \"l_ankle\": {\"z\":pose_3d[8][0], \"y\":pose_3d[8][1], \"x\":pose_3d[8][2]},\n",
    "                \"r_hip\": {\"z\":pose_3d[12][0], \"y\":pose_3d[12][1], \"x\":pose_3d[12][2]},\n",
    "                \"r_knee\": {\"z\":pose_3d[13][0], \"y\":pose_3d[13][1], \"x\":pose_3d[13][2]},\n",
    "                \"r_ankle\": {\"z\":pose_3d[14][0], \"y\":pose_3d[14][1], \"x\":pose_3d[14][2]}\n",
    "            }\n",
    "        }\n",
    "        poses.append(frame_pose)\n",
    "    i += 1\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"poses.json\", \"w\") as f:\n",
    "\tjson.dump(poses, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
